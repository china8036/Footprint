- [Ray: Distributed Training - 实现分析](#ray-distributed-training---实现分析)
  - [3. Refer Links](#3-refer-links)

# Ray: Distributed Training - 实现分析


## 3. Refer Links

[Ray Github](https://github.com/ray-project/ray)

[Ray Docs](https://ray.readthedocs.io/en/latest/index.html)

[Ray: A Distributed Framework for Emerging AI Applications](https://arxiv.org/pdf/1712.05889.pdf)

[Real-Time Machine Learning: The Missing Pieces](https://arxiv.org/pdf/1703.03924.pdf)

TODO:

[Ray: Memory Management](https://ray.readthedocs.io/en/latest/memory-management.html)

[Ray --内部运行机制、对象存储中对象的存储和容错](https://blog.csdn.net/weixin_43255962/article/details/89684608)

[Ray- Plasma 的对象存储、资源管理（cpu，gpu）和临时文件](https://blog.csdn.net/weixin_43255962/article/details/89712162)

[Ray源码解析之整体逻辑结构](http://whatbeg.com/2019/04/16/raysource-overall.html?utm_source=tuicool&utm_medium=referral)

[Ray源码解析之调度部分](http://whatbeg.com/2019/04/16/raysource-schedule.html)

[Ray源码解析之Task部分](http://whatbeg.com/2019/04/16/raysource-task.html)

[Ray 源码解析（一）：任务的状态转移和组织形式](https://zhuanlan.zhihu.com/p/75496780)

[Ray 源码解析（二）：资源抽象和调度策略](https://zhuanlan.zhihu.com/p/77520714)