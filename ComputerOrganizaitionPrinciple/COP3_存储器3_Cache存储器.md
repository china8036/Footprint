- [计算机组成原理：存储器 - Cache 存储器](#计算机组成原理存储器---cache-存储器)
  - [1. 基本概念](#1-基本概念)
  - [2. 运行过程](#2-运行过程)
  - [3. 地址映射](#3-地址映射)
    - [3.1. 全相联映射方式](#31-全相联映射方式)
    - [3.2. 直接映射方式](#32-直接映射方式)
    - [3.3. 组相联映射方式](#33-组相联映射方式)
  - [4. 替换策略](#4-替换策略)
    - [4.1. LFU](#41-lfu)
    - [4.2. LRU](#42-lru)
    - [4.3. 随机替换](#43-随机替换)
  - [5. 多级 Cache](#5-多级-cache)
  - [6. Refer Links](#6-refer-links)

# 计算机组成原理：存储器 - Cache 存储器

## 1. 基本概念

Cache 存储器是一种高速缓冲存储器，是为了解决 CPU 和主存之间的速度不匹配问题而采用的一项重要技术，其**基本原理基于程序运行中具有的空间局部性和时间局部性特征**。Cache 是介于 CPU 和主存之间的小容量存储器（主存容量配置几百 MB 的情况下，cache 的典型值是几百 KB），但存取速度比主存快，Cache 能高速地向 CPU 提供指令和数据，从而加快了程序的执行速度。

Cache 存储器由高速的 SRAM 组成，为追求高速，包括管理在内的全部功能都由硬件实现，因而对程序员是透明的。

随着半导体器件集成度的进一步提高，目前的 cache 存储器已放入到 CPU 中，其工作速度接近于 CPU 的速度，从而能组成两级以上的多级 Cache 系统（早期的一级 Cache 在 CPU 内，二级在主板上，现在的 CPU 内带 L1 Cache 和 L2 Cache）。

## 2. 运行过程

CPU 与 Cache 之间的数据传送是以字为单位；主存与 Cache 之间的数据传送是以块为单位。

CPU 读主存时，便把地址同时送给 Cache 和主存，Cache 控制逻辑依据地址判断此字是否在 Cache 中，若在此字立即传送给 CPU，否则，则用主存读周期把此字从主存读出送到 CPU，与此同时，把含有这个字的整个数据块从主存读出送到 Cache 中。

## 3. 地址映射

与主存容量相比，Cache 的容量很小，它保存的内容只是主存内容的一个子集，且 Cache 与主存的数据交换是以块为单位。为了把主存块放到 Cache 中，必须应用某种方法把主存地址定位到 Cache 中，这个过程称为地址映射。

地址映射过程一般由硬件直接实现，因此映射变换很快，对于软件开发人员 Cache 是透明的，几乎感觉不到 Cache 的存在。

Cache 地址映射方式要考虑：
- 硬件是否容易实现
- 地址变换的速度是否快
- 主存空间的利用率是否高
- 主存装入一块时，发生冲突的概率

一般有全相联映射方式、直接映射方式、组相联映射方式。

### 3.1. 全相联映射方式

映射方法：
- 多对多映射
- 在全相联映射中，将主存中每一个块的地址（块号）与块的内容（字）一起存于 Cache 的行中，其中块地址存于 Cache 行的标记部分，从而可使主存的每一个块直接拷贝到 Cache 的任意一行上，非常灵活。
- CPU 给出访问地址后，也将地址分为两部分（块号和字），比较电路块号与 Cache 表中的标记进行比较，相同表示命中，访问相应单元；如果没有命中访问内存，CPU 直接访问内存，并将被访问内存的相对应块写入 Cache。

优缺点：
- 优点：冲突概率小，Cache 的利用高。
- 缺点：比较器电路难以设计和实现，需要一个访问速度很快代价高的相联存储器，因此只适用于小容量的 Cache。

应用场景：只适用于小容量的 Cache。

### 3.2. 直接映射方式

映射方法：
- 一对多映射
- 一个主存块只能拷贝到 Cache 的一个特定行位置上去，Cache 的行号 i 和主存的块号 j 有如下关系：`i = j mod m`。
- 利用行号选择相应行，把行标记与 CPU 访问地址进行比较，相同表示命中，访问 Cache，如果没有命中，访问内 存，并将相应块写入 Cache。

e.g. cache 容量 16 字，主存容量 256 字，则地址 2，18，34…..242 等都存放在 cache 的地址 2 内，如果第一次 2 在 cache 中，下次访问 34 内容，则不管 cache 其他位置的内容访问情况，都会引起 2 块内容的替换。

优缺点：
- 优点：比较电路少 m 倍线路，所以硬件实现简单，Cache 地址为主存地址的低几位，不需变换。
- 缺点：每个主存块只有一个固定的行位置可以存放，发生冲突的概率高。发生冲突时需要将原先存入的行换出去，但可能过一段时间又需要换入，频繁的置换会使 Cache 的效率降低。因此，直接映射方式通常用于大容量 Cache，更多的行数可减小冲突发生的概率。

应用场景：适合大容量 Cache。

### 3.3. 组相联映射方式

映射方法：组相联映射是全相联映射方式和直接映射方式的折衷方案，这种方式将 Cache 分成 u 组，每组 v 行，组间采用直接映射方式，而组内采用全相联映射方式，常称为 v 路组相联 Cache。

优缺点：组相联映射是全相联映射方式和直接映射方式的折衷方案，它适度地兼顾了二者的优点又尽量避免二者的缺点，因此被普遍采用。

## 4. 替换策略

当一个新的主存块需要拷贝到 Cache，而允许存放此块的行位置都被其它主存块占满时，就要产生替换。

替换策略与 Cache 的组织方式紧密相关：
- 对于直接映射 Cache：因一个主存块只有一个特定的行位置可存放，所以只要把此特定位置上的原主存块换出 Cache 即可。
- 对于全相联 Cache 或组相联 Cache：需要从允许存放新主存块的若干特定行中选取一行换出，如何选取的策略称为替换算法 / 替换策略，一般由硬件实现。

### 4.1. LFU

LFU（最不经常使用替换算法）：被访问的行计数器增加 1，换值小的行，不能反映近期 cache 的访问情况。

### 4.2. LRU

LRU（近期最少使用替换算法）：被访问的行计数器置 0，其他的计数器增加 1，换值大的行，符合 cache 的工作原理。

### 4.3. 随机替换

随机替换：随机替换策略实际上是不要什么算法，从特定的行位置中随机地选取一行换出即可。这种策略在硬件上容易实现，且速度也比前两种策略快。缺点是随意换出的数据很可能马上又要使用，从而降低命中率和 cache 工作效率。但这个不足随着 cache 容量增大而减小。随机替换策略的功效只是稍逊于前两种策略。

## 5. 多级 Cache

为进一步缩小现代处理器高时钟频率和访问 DRAM 相对较慢之间的差距，高性能微处理器可支持附加一级的 Cache，即 L2 Cache。

- 二级 Cache (L2 Cache) 位于处理器芯片内或是位于处理器芯片外单独的一组 SRAM，当访问主 cache 缺失后就会访问它；如果二级 Cache 包含所请求的数据，缺失损失就是二级 Cache 的访问时间，相比主存的访问时间要短得多。
- 如果一级 Cache (L1 Cache) 和二级 Cache (L2 Cache) 都不包含这个数据，就需要访问主存储器，产生更大的缺失损失。

测试数据表明，有二级 Cache 的处理器性能是没有二级 Cache 的处理器性能的 2.8 倍。

随着 CPU 制造工艺的发展，二级缓存也能轻易的集成在 CPU 内核中，容量也在逐年提升。用集成在 CPU 内部与否来定义一、二级缓存，已不确切。而且随着二级缓存被集成入 CPU 内核中，以往二级缓存与 CPU 大差距分频的情况也被改变，此时其以相同于主频的速度工作，可以为 CPU 提供更高的传输速度。同一核心的 CPU 高低端之分往往也是在二级缓存上有差异，由此可见二级缓存对于 CPU 的重要性。

P.S.
- L1 和 L2 Cache 的区别，它们的构造一样吗？

  答案是否定的，虽然它们都是由 CAM（Content Addressable Memory ）为主体的 tag 和 SRAM 组成的，但是区别却是明显的：L1（先不考虑指令和数据 L1 的不同）是为了更快的速度访问而优化过的，它用了更多 / 更复杂 / 更大的晶体管，从而更加昂贵和更加耗电；L2 相对来说是为提供更大的容量优化的，用了更少 / 更简单的晶体管，从而相对便宜和省电。同样的道理还可以推广到 L2 和 L3 上。

- Cache 为什么不会做的很大？

  ![image](http://img.cdn.firejq.com/jpg/2019/2/2/bd74b2b878289e954512b971b0188482.jpg)

  从图中可以看出，随着 L2 容量的增加，开始时 L2 和整体命中率快速提高，这表明提高 L2 容量效用很明显。随后 L2 的命中率在容量增加到 64KB 后增长趋缓，而整体命中率也同时趋缓，最后甚至基本不大变化了。增加同样的晶体管，而受益却越来越少，出现了边际效用递减的问题。

## 6. Refer Links

[Cache 为什么有那么多级？为什么一级比一级大？是不是 Cache 越大越好？](https://zhuanlan.zhihu.com/p/32058808)