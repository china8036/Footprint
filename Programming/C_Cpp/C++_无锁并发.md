- [C++ 无锁并发 (Lock Free Concurrent)](#c-%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91-lock-free-concurrent)
  - [1. 原子操作](#1-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C)
    - [1.1. 基本概念](#11-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)
    - [1.2. 原子操作](#12-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C)
    - [1.3. C++ CAS 实现](#13-c-cas-%E5%AE%9E%E7%8E%B0)
    - [1.4. CAS 缺点](#14-cas-%E7%BC%BA%E7%82%B9)
  - [2. 双缓冲队列](#2-%E5%8F%8C%E7%BC%93%E5%86%B2%E9%98%9F%E5%88%97)
  - [3. 环形缓冲区](#3-%E7%8E%AF%E5%BD%A2%E7%BC%93%E5%86%B2%E5%8C%BA)
    - [3.1. 基本概念](#31-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5)
    - [3.2. 实际应用](#32-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8)
    - [3.3. 无锁并发](#33-%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91)
  - [4. 应用](#4-%E5%BA%94%E7%94%A8)
  - [5. Refer Links](#5-refer-links)

# C++ 无锁并发 (Lock Free Concurrent)

## 1. 原子操作

### 1.1. 基本概念

无锁操作是 CPU 提供的指令级的功能，它会对内存数据做总线级别的加锁，操作期间还会禁止 CPU 中断，以保证操作的原子性。

一个通用的无锁队列似乎相当容易实现。问题的根源在于相同的变量必然需要与多个线程共享。例如，采取一种基于链表的通用方法：至少需要共享列表的头部和尾部，因为消费者都需要能够读取和更新头部，而生产者都需要能够更新尾部。当多个线程需要更新队列但要求保持队列处于一致的状态下肯定会导致资源分互斥访问。例如，如果消费者从队列中读取最后一个任务节点并仅更新头部，尾指针不应该指向它，因为该任务节点很快就会被释放。但是消费者可能被操作系统打断，在更新尾部之前暂停几毫秒，在这段时间内，尾指针可以被另一个生产者更新，然后第一个消费者将其设置为 null 就太晚了。

解决共享数据安全访问是无锁编程的关键。通常最好的方法是设想一种算法，它不需要首先更新多个变量以保持一致性，或者增量更新仍然使数据结构保持一致状态。不同的技巧可以使用，如在指针的最后两位存储额外的状态，指针和引用计数等，但像这些方法只能越走越远，真正的解决办法是开发算法本身。

使用锁来保护队列会序列化所有的操作：任何时刻仅有一个核心能够更新队列，其他核心则必须等到轮到它们。这最终产生出一个序列化瓶颈，并且很快的摧毁了性能。一个增强可伸缩性的可能性是将锁替换为无锁的同步，该方法使用原子指令来直接操作队列，故而能减少序列化的部分（序列化依然是个问题，因为硬件的缓存一致机制亦会序列化这些更新同一个内存地址的原子指令）。

无锁式同步（亦被称作非阻塞式同步）利用原子指令而不是锁来直接操作共享的数据。大部分无锁算法利用多核处理器上的 CAS（Compare-And-Swap）指令（或者类似的指令）。一个 CAS 操作需要三个操作数：一个内存地址 addr，一个旧值 old 以及一个新值 new。该指令原子地将储存在 addr 中的数值从 old 更新至 new，如果储存在 addr 中的值不等于 old，那么 CAS 将不会更新内存而失败。

基于 CAS 操作的无锁算法利用 CAS 循环的模式来进行同步：一个核心读取共享状态，计算出新值，然后利用 CAS 来将共享内存更新至新值。若 CAS 指令成功了，那么这次的读取 - 计算 - 更新操作序列看上去就是成功了，若指令失败则该核心需要重试。许多基本数据结构的无锁式实现，例如队列、堆栈以及优先队列，都有着类似的思想，它们都利用某种原子指令来实现整个数据结构的更新操作。

![image](http://otaivnlxc.bkt.clouddn.com/jpg/2018/8/9/0e4f5d4739752aa33393d86448e7ba91.jpg)

当没有（或很少）竞争之时，原子指令（有时是多条）的使用会造成无意义的 CAS 消耗，可能使无锁式同步比基于锁的解决方案还要慢。而在高竞争之时，无锁式同步有效率更高的潜质，因为其消除了临界路径上锁获取以及锁释放的操作，仅留下了对数据结构的操作。但需要注意的是，若在 CAS 循环中包含了大量的回滚操作，可能会导致其效率要比基于锁的同步更低。

![image](http://otaivnlxc.bkt.clouddn.com/jpg/2018/8/9/da5a79bc6a0278f3be4c10fb4499abfe.jpg)  

另外，无锁式算法保证了某一操作总是能够完成，故而在高负荷下仍能表现优异，而基于锁的算法却可能由于操作系统优先抢占持锁的线程而停止。

**在实践中，无锁同步机制往往不能够超过基于锁的同步**。这里较差性能的原因则是因为**CAS 失败**：随着并发量增加，另一个 CAS 操作插入到一个核心的读取 - 计算 - 更新序列之间的几率也增加了，这会让该核心发生 CAS 失败。像这样失效的 CAS 操作向临界路径上累加了许多无用功。虽然这些失效的 CAS 操作并不更改内存，执行它们依旧需要获取该变量对应缓存列的排他访问。这让尔后获取该缓存列并成功更新的操作之时间延长。

如果有方法能使所有的算子指令都能完成操作，便能够极大地提升性能。但由于 CAS 失效的固有性，我们如何才能做到这一点？

关键的观察在于 x86 架构支持几个总是成功的原子指令。其中一个是 FAA（Fetch-And-Add），该指令原子地将整数累加到变量中，然后返回变量储存的旧值。LCRQ（Linked Concurrent Ring Queue）就是一种基于 FAA 而不是 CAS 的无锁队列设计，它利用了 FAA 指令将线程分布到队列中的对象上，从而让其能够快速且并行地入队出队。LCRQ 一般执行一个 FAA 指令来获取自己在队列中的位置，从而提供了完全一致的行为。

无限的数组首先被换成一个有 R 个元素的并发环形（循环数组）队列，缩写为 CRQ。head 和 tail 下标依然严格单调增加，不过此时下标与 R 取模后的数值指明了其指向的位置。由于现在有超多一个的入队线程和出队线程能够并发地访问一个元素，CRQ 使用了更为复杂的基于 CAS 的协议来同步每个元素。这个协议让一个操作可以不必等待那些 FAA 返回较小下标的，指向同一个位置的其他操作的完成。

CRQ 的关键性能特点是在公共的快速路径上，操作只包含一个 FAA 指令。LCRQ 算法基于 CRQ 来阻止活锁问题，并处理 CRQ 填满的情况。LCRQ 本质上是 Michael 和 Scott 的链表队列 [11]，这个队列里每个节点都是一个 CRQ。被填满或者遭遇活锁的 CRQ 会更接近入队操作，然后添加一个新的 CRQ 到队列并在其上工作。LCRQ 的大部分工作因此发生在各个 CRQ 里，让列表的头尾指针竞争（CAS 失效）不再是个问题。

<!-- ////////////////////////// -->

多线程程序设计似乎没有一个统一的答案：pthreads，原子指令，无锁结构，都不是放之四海而皆准的办法。但有一个可以肯定的就是你的设计：**如何规避竞争**。

比方说，一个依赖全局多生产者多消费者队列 (MPMC) 的程序不可能有很好的多核适应性，因为这个队列的极限吞吐取决于 CPU 的同步 cache 延时，lock-free 和 wait-free 也解决不了。更好的解决方法是规避全局竞争，比如用多个 SPMC 或多个 MPSC 队列，甚至多个 SPSC 队列代替，在源头就规避掉竞争。也许这就是最重要的法则。

<!-- ////////////////////////// -->

**原子操作（如 CAS）实现的是 lock free，但不是 wait free**。

### 1.2. 原子操作

- [CAS](http://en.wikipedia.org/wiki/Compare-and-swap)
- [Fetch And Add](http://en.wikipedia.org/wiki/Fetch-and-add)
- [Test-and-set](http://en.wikipedia.org/wiki/Test-and-set)
- [Test and Test-and-set](http://en.wikipedia.org/wiki/Test_and_Test-and-set)

### 1.3. C++ CAS 实现

- GCC CAS

  GCC4.1+ 版本中支持 CAS 的原子操作（完整的原子操作可参看 [GCC Atomic Builtins](http://gcc.gnu.org/onlinedocs/gcc-4.1.1/gcc/Atomic-Builtins.html)）
  ```cpp
  bool __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...)
  type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...)
  ```

- Windows CAS

  在 Windows 下，你可以使用下面的 Windows API 来完成 CAS（完整的 Windows 原子操作可参看 MSDN 的 [InterLocked Functions](http://msdn.microsoft.com/en-us/library/windows/desktop/ms686360(v=vs.85).aspx#interlocked_functions)）：
  ```cpp
  InterlockedCompareExchange (__inout LONG volatile *Target,
                                  __in LONG Exchange,
                                  __in LONG Comperand);
  ```                                

- C++11 CAS

  C++11 STL 中的 atomic 类的函数可以让你跨平台（完整的 C++11 的原子操作可参看 [Atomic Operation Library](http://en.cppreference.com/w/cpp/atomic)）:
  ```cpp
  template< class T >
  bool atomic_compare_exchange_weak( std::atomic* obj,
                                    T* expected, T desired );
  template< class T >
  bool atomic_compare_exchange_weak( volatile std::atomic* obj,
                                    T* expected, T desired );
  ```

- C++ Boost CAS
  ```cpp

  ```

### 1.4. CAS 缺点

- ABA 问题

  CAS 看起来很美，但这种操作显然无法涵盖并发下的所有场景，并且 CAS 从语义上来说也不是完美的，存在这样一个逻辑漏洞：如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？如果在这段期间它的值曾经被改成了 B，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个漏洞称为 CAS 操作的"ABA"问题。java.util.concurrent 包为了解决这个问题，提供了一个带有标记的原子引用类"AtomicStampedReference"，它可以通过控制变量值的版本来保证 CAS 的正确性。不过目前来说这个类比较"鸡肋"，大部分情况下 ABA 问题并不会影响程序并发的正确性，如果需要解决 ABA 问题，使用传统的互斥同步可能回避原子类更加高效。

- 循环时间长开销大
  
  自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。如果 JVM 能支持处理器提供的 pause 指令那么效率会有一定的提升，pause 指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）, 使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起 CPU 流水线被清空（CPU pipeline flush），从而提高 CPU 的执行效率。

- 只能保证一个共享变量的原子操作

  当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量 i＝2,j=a，合并一下 ij=2a，然后用 CAS 来操作 ij。从 Java1.5 开始 JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。

## 2. 双缓冲队列

TODO:

http://guoyb.com/2018/03/17/double-buffer/

http://rrsongzi-gmail-com.iteye.com/blog/696627

https://program-think.blogspot.com/2009/04/producer-consumer-pattern-4-double.html

所谓双 buffer 技术，其实就是准备两个 Obj，一个用来读，一个用来写。写完成之后，原子交换两个 Obj；之后的读操作，都放在交换后的读对象上，而原来的读对象，在原有的“读操作”完成之后，又可以进行写操作了。

所谓“双缓冲区”，故名思义就是要有 2 个缓冲区（简称 A 和 B）。这 2 个缓冲区，总是一个用于生产者，另一个用于消费者。当 2 个缓冲区都操作完，再进行一次切换（先前被生产者写入的转为消费者读出，先前消费者读取的转为生产者写入）。由于生产者和消费者不会同时操作同一个缓冲区（不发生冲突），所以就不需要在读写每一个数据单元的时候都进行同步 / 互斥操作（又一次展现了【空间换时间】的优化思路）。

双缓冲区的多种状态：
- 缓冲区都在使用（并发读写）

  大多数情况下，生产者和消费者都处于并发读写状态。不妨设生产者写入 A，消费者读取 B。在这种状态下，生产者拥有锁 La；同样的，消费者拥有锁 Lb。由于俩缓冲区都是处于独占状态，因此每次读写缓冲区中的元素（数据单元）都【不需要】再进行加锁、解锁操作。这是节约开销的主要来源。

- 单个缓冲区空闲

  由于两个并发实体的速度会有差异，必然会出现一个缓冲区已经操作完，而另一个尚未操作完。不妨假设生产者快于消费者。在这种情况下，当生产者把 A 写满的时候，生产者要先释放 La（表示它已经不再操作 A），然后尝试获取 Lb。由于 B 还没有被读空，Lb 还被消费者持有，所以生产者进入发呆（Suspend）状态。

- 缓冲区的切换

  过了若干时间，消费者终于把 B 读完。这时候，消费者也要先释放 Lb，然后尝试获取 La。由于 La 刚才已经被生产者释放，所以消费者能立即拥有 La 并开始读取 A 的数据。而由于 Lb 被消费者释放，所以刚才发呆的生产者会缓过神来（Resume）并拥有 Lb，然后生产者继续往 B 写入数据。经过上述几个步骤，俩缓冲区完成了对调，变为：生产者写入 B，消费者读取 A。

存在的问题
- 本来单个缓冲区的生产者 / 消费者问题就已经是教科书的经典问题了，现在搞出俩缓冲区，所以就更加耗费脑细胞了。一不小心，就会搞出些并发的 Bug，而且并发的 Bug 还很难调试和测试（这也就是为啥不要轻易使用该玩意儿的原因）。
- 假如把前面介绍的操作步骤调换一下顺序：生产者或消费者在操作完当前的缓冲区之后，先去获取另一个缓冲区的锁，再来释放当前缓冲区的锁。那会咋样捏？一旦两个并发实体【同时】处理完各自缓冲区，然后【同时】去获取对方拥有的锁，那就会出现典型的死锁。

## 3. 环形缓冲区

### 3.1. 基本概念

![image](http://otaivnlxc.bkt.clouddn.com/jpg/2018/8/17/7e9dcdab0608057b944fb4bbd24a39ce.jpg)

网络编程中有这样一种场景：需要应用程序代码一边从 TCP/IP 协议栈接收数据（reading data from socket），一边解析接收的数据。具体场景例如：用户点击 Youtube 或优酷网站上的视频内容，这时用户 PC 上的播放软件就是一边接收数据一边对数据进行解码并播放的。这样的场景的存在如下约束：
- 必须边接收数据，边对数据进行解析，不能等待到数据全部接收完整后才解析（用户等待的时间与体验成反比）。
- 数据为流式数据（如 TCP 承载），需对接收到的数据进行定界分析，将数据转化为可被应用程序解析的结构化数据。
- 数据的解析需要兼顾性能和内存空间的利用效率（如果减少内存拷贝，分配适当大小的缓存空间）。

在通信程序中，**环形缓冲区 (circular buffer / ring buffer / circular queue) **是一种用于表示一个固定尺寸、头尾相连的缓冲区的数据结构，适合缓存数据流。它经常作为数据结构来存放通信中发送和接收的数据，可以向通信程序提供对缓冲区的互斥访问。

环形缓冲区通常有一个读指针（tail）和一个写指针（head）。读指针指向环形缓冲区中可读的数据，写指针指向环形缓冲区中可写的缓冲区。通过移动读指针和写指针就可以实现缓冲区的数据读取和写入。

在通常情况下，环形缓冲区的读用户仅仅会影响读指针，而写用户仅仅会影响写指针。因此，**如果仅仅有一个读用户和一个写用户，那么不需要添加互斥保护机制就可以保证数据的正确性。如果有多个读写用户访问环形缓冲区，那么必须添加互斥保护机制来确保多个用户互斥访问环形缓冲区。**

圆形缓冲区的一个有用特性是：**当一个数据元素被用掉后，其余数据元素不需要移动其存储位置。相反，一个非圆形缓冲区（例如一个普通的队列）在用掉一个数据元素后，其余数据元素需要向前搬移。**

圆形缓冲区适合于事先明确了缓冲区的最大容量的情形。扩展一个圆形缓冲区的容量，需要搬移其中的数据。因此一个缓冲区如果需要经常调整其容量，用链表实现更为合适。

写操作覆盖圆形缓冲区中未被处理的数据在某些情况下是允许的。特别是在多媒体处理时。例如，音频的生产者可以覆盖掉声卡尚未来得及处理的音频数据。

环形缓冲区特别适合于 FIFO 类型数据的处理，利用它可以不拷贝内存完成缓冲上数据的解析，提高数据解析效率。

环形缓冲区在处理异步 IO 时非常实用。它们可以在一端接收随机长度和区间的数据，在另一端以相同长度和区间提供密致的数据块。它们是 Queue 数据结构的变体，但是它针对于字节块而不是一系列指针。

若数据读取函数采用单字节读、取模数计算偏移的方式，则可能带来性能上的损耗，该问题可以通过增加判断或以做位运算等机制来解决，但同时也增加了实现逻辑的复杂度。

环形缓冲区的不足之处在于需要预先估计数据缓冲的大小，并分配比预估大小大一个数量级的缓存空间。一种可能的解决办法是增加检测机制，若发现缓冲太小，则动态调大缓冲的大小，但这同时又可能导致频繁的调整内存大小，带来性能的下降。

### 3.2. 实际应用

- Linux 内核文件 kfifo.h 和 kfifo.c 中，就实现了一个环形缓冲区 (ring buffer)。
- Java Disruptor 就是基于 ring buffer 实现的无锁队列。

### 3.3. 无锁并发

环形缓冲只能保证两人读和写之间无 lock，但如果多人同时读 - 读、或写 - 写，还是必须有 lock。另外，为了判断是否满，也必须要有 lock，只不过这个 lock 可以通过技巧使得 lock 时间极短、高效，可以忽略。

ring buffer 的 lock free（绝对无锁) 必须有三个前提，否则就不是线程安全的：
- cpu 支持内存栅栏
- 数据的地址必须是四对齐的
- 一生产者一消费者

但**环形缓冲区可以有 lock free 的实现**。具体原因在于，**每一个 producer 或者 consumer，都不需要对整个数据结构独占，不需要对整个数据结构加锁。他们做的都只是移动 head、tail，这样自然可以通过对 head 和 tail 的原子操作实现**。

具体的实现方法可参考基于环形缓冲区的无锁设计的 [Disruptor](https://tech.meituan.com/disruptor.html#Disruptor%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88)，它通过将多个生产者或多个消费者的读写进行分离，实现了无锁的环形队列。这样因为每个线程独占一块空间写入数据，就不会有线程同步问题，唯一需要同步的地方是分配写入空间和更新可读区域。但是这两个操作都是非常简单的加操作，加锁太浪费，所以 Disruptor 直接使用原子变量加自旋等待来同步，获取极高的性能。 

## 4. 应用

内存数据库领域用的很多：
- MemSQL 用 Lock Free Skip List 做索引：The Story Behind MemSQL’s Skiplist Indexes
- [SQL SERVER 内存存储引擎 Hekaton 用 Lock Free Bw-Tree 做索引](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/bw-tree-icde2013-final.pdf)
- [HyPer 的并行查询引擎大量的应用了 Lock Free 数据结构，如使用 Lock Free 的 Hash Table 实现 Hash Join](http://db.in.tum.de/~leis/papers/morsels.pdf)
- [DB2 BLU 的并行查询引擎](http://db.disi.unitn.eu/pages/VLDBProgram/pdf/industry/p773-barber.pdf)
- OceanBase 也大量的使用 Lock Free

为什么传统数据库不用呢？因为瓶颈在磁盘，Lock Free 增加的性能几乎可以忽略不计，但是在内存数据库中是可以大幅度提高性能的。

## 5. Refer Links

[一种高性能无锁队列设计](https://blog.csdn.net/u011305688/article/details/79407001)

[提升多核程序中同步操作的可伸缩性](http://coyee.com/article/11114-scaling-synchronization-in-multicore-programs)

[躲不开的多线程](https://www.cnblogs.com/gistao/p/4463934.html)

[无锁队列的实现](https://coolshell.cn/articles/8239.html)

[CAS 中的 ABA 问题](http://www.itboth.com/d/aqEVVr/cas-c++)

[JAVA CAS 原理深度分析](http://zl198751.iteye.com/blog/1848575)

[环形缓冲区的应用 ringbuffer](https://blog.csdn.net/u011046042/article/details/51853535)

[Wikipedia 环形缓冲区](https://zh.wikipedia.org/wiki/%E7%92%B0%E5%BD%A2%E7%B7%A9%E8%A1%9D%E5%8D%80)

[linux 网络编程 --Circular Buffer(Ring Buffer) 环形缓冲区的设计与实现](https://blog.csdn.net/yusiguyuan/article/details/18368095)

[环形缓冲区的设计及其在生产者消费者模式下的使用](https://www.cnblogs.com/zengzy/p/5139582.html)

[环形缓冲区为什么是 lock-free 的？](https://www.zhihu.com/question/28131353)

TODO:

[C++ 的无锁数据结构在工业界有真正的应用吗？](https://www.zhihu.com/question/52629893)
